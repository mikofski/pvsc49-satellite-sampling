{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67047cb3",
   "metadata": {},
   "source": [
    "# Effect of instantaneous weather sampling rate on subhourly clipping errors - SURFRAD\n",
    "These notebooks resample the SURFRAD network data at different frequencies to simulate satellite data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "336cc772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "import pathlib\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pvlib\n",
    "import rdtools\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(font_scale=1.5, rc={'figure.figsize': (16, 10)})\n",
    "mpl.rcParams['figure.figsize'] = (16, 10)\n",
    "\n",
    "DAYMINUTES = 24*60\n",
    "KELVINS = 273.15\n",
    "MAX_GHI_RATIO = 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4185f873-f149-4c36-95f8-b841d7b9791e",
   "metadata": {},
   "source": [
    "## Some useful functions\n",
    "* `read_surfrad_year` just reads all daily files from a yearly surfrad folder\n",
    "* `estimate_air_temp` is for years that have incomplete air temperature data like 1995."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fc6ce13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_surfrad_year(surfrad_year_path):\n",
    "    data = [pvlib.iotools.read_surfrad(f) for f in surfrad_year_path.iterdir()]\n",
    "    dfs, heads = zip(*data)\n",
    "    df = pd.concat(dfs)\n",
    "    header = heads[0]\n",
    "    return df, header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cb81327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_air_temp(year_start, surfrad, lat, lon, cs, max_ghi_ratio=MAX_GHI_RATIO):\n",
    "    \"\"\"\n",
    "    Use clear sky temps scaled by daily ratio of measured to clear sky global\n",
    "    insolation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    year_start : str\n",
    "        SURFRAD data year\n",
    "    surfrad : pandas.DateFrame\n",
    "        surfrad data frame\n",
    "    lat : float\n",
    "        latitude in degrees north of equator [deg]\n",
    "    lon : float\n",
    "        longitude in degrees east of prime meridian [deg]\n",
    "    cs : pandas.DataFrame\n",
    "        clear sky irradiances [W/m^2]\n",
    "    max_ghi_ratio : float\n",
    "        daily GHI to clear sky GHI ratio is clipped at this limit\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    est_air_temp : pandas.DataFrame\n",
    "        estimated air temperature in Celsius [C]\n",
    "    temp_adj : pandas.Series\n",
    "        temperature adjustment [C}\n",
    "    ghi_ratio : pandas.Series\n",
    "        ratio of  daily SURFRAD to clearsky GHI insolation\n",
    "    daily_delta_temp : numpy.array\n",
    "        daily temperature range, max - min, in Kelvin [K]\n",
    "    cs_temp_air : pandas.Series\n",
    "        clear sky air temperatures in Celsius [C]\n",
    "\n",
    "    \"\"\"\n",
    "    daze = 367 if calendar.isleap(int(year_start)) else 366\n",
    "    # create a leap year of minutes for the given year at UTC\n",
    "    year_minutes = pd.date_range(\n",
    "        start=year_start, freq='T', periods=daze*DAYMINUTES, tz='UTC')\n",
    "    # clear sky temperature\n",
    "    cs_temp_air = rdtools.clearsky_temperature.get_clearsky_tamb(\n",
    "        year_minutes, lat, lon)\n",
    "    # organize by day\n",
    "    cs_temp_daily = cs_temp_air.values.reshape((daze, DAYMINUTES)) + KELVINS\n",
    "    # get daily temperature range\n",
    "    daily_delta_temp = np.array([td.max()-td.min() for td in cs_temp_daily])\n",
    "    daily_delta_temp = pd.Series(\n",
    "        daily_delta_temp, index=cs_temp_air.resample('D').mean().index)\n",
    "    # calculate ratio of daily insolation versus clearsky\n",
    "    ghi_ratio = surfrad.ghi.resample('D').sum() / cs.ghi.resample('D').sum()\n",
    "    # limit ghi ratio and remove +/-inf\n",
    "    ghi_ratio = np.clip(ghi_ratio, 0, max_ghi_ratio)\n",
    "    ghi_ratio = ghi_ratio.rename('ghi_ratio')\n",
    "    # apply ghi ratio to next day, wrap days to start at day 1\n",
    "    day1 = ghi_ratio.index[0]\n",
    "    ghi_ratio.index = ghi_ratio.index + pd.tseries.frequencies.to_offset('1D')\n",
    "    # set day 1 estimated air temp equal to last day\n",
    "    ghi_ratio[day1] = ghi_ratio.iloc[-1]\n",
    "    # fix day 1 is added last, so out of order\n",
    "    ghi_ratio = ghi_ratio.sort_index()\n",
    "    # scale daily temperature delta by the ratio of insolation from day before\n",
    "    temp_adj = (ghi_ratio - 1.0)*daily_delta_temp[ghi_ratio.index]  # use next day\n",
    "    # where GHI ratio is not finite, use unadjusted clear sky temp\n",
    "    temp_adj = temp_adj.where(ghi_ratio>0, 0)\n",
    "    temp_adj = temp_adj.rename('temp_adj')\n",
    "    # interpolate smoothly, but fill forward minutes in last day\n",
    "    est_air_temp = pd.concat(\n",
    "        [cs_temp_air,\n",
    "         ghi_ratio.resample('1min').interpolate(),\n",
    "         temp_adj.resample('1min').interpolate()], axis=1).pad()\n",
    "    # Tadj = Tcs + (GHI/CS_GHI - 1) * DeltaT \n",
    "    # if GHI/CS_GHI > 1 then adjustment > DeltaT\n",
    "    est_air_temp['Adjusted Temp (C)'] = (\n",
    "        est_air_temp['Clear Sky Temperature (C)'] + est_air_temp.temp_adj)\n",
    "    return est_air_temp, temp_adj, ghi_ratio, daily_delta_temp, cs_temp_air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dac2a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there really a \u001b[1m\u001b[91m\"SURFRAD\"\u001b[0m\u001b[0m directory? \u001b[1m\u001b[92mTrue ✓\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# get glob of weather files\n",
    "surfrad_dir = pathlib.Path('../../SURFRAD')\n",
    "print(f'Is there really a \\33[1m\\33[91m\"SURFRAD\"\\33[0m\\33[0m directory?'\n",
    "      f' \\33[1m\\33[92m{surfrad_dir.exists()} \\u2713\\33[0m\\33[0m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3727b637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there really a \u001b[1m\u001b[91m\"..\\..\\SURFRAD\\Bondville_IL\"\u001b[0m\u001b[0m directory? \u001b[1m\u001b[92mTrue ✓\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# get glob of Bondville, IL, yearly files\n",
    "weather_dir = \"Bondville_IL\"\n",
    "weather_path = surfrad_dir / weather_dir\n",
    "print(f'Is there really a \\33[1m\\33[91m\"{weather_path}\"\\33[0m\\33[0m directory?'\n",
    "      f' \\33[1m\\33[92m{weather_path.exists()} \\u2713\\33[0m\\33[0m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb721491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1995',\n",
       " '1996',\n",
       " '1997',\n",
       " '1998',\n",
       " '1999',\n",
       " '2000',\n",
       " '2001',\n",
       " '2002',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007',\n",
       " '2008',\n",
       " '2009',\n",
       " '2010',\n",
       " '2011',\n",
       " '2012',\n",
       " '2013',\n",
       " '2014',\n",
       " '2015',\n",
       " '2016',\n",
       " '2017',\n",
       " '2018',\n",
       " '2019',\n",
       " '2020',\n",
       " '2021']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a glob of years\n",
    "weather_years = weather_path.iterdir()\n",
    "years = [p.parts[-1] for p in weather_years]\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c198edd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1995 has 0 out of 175200.0 expected with 3.0-min timestep (year complete = 0%)\n",
      "1996 has 56460 out of 175680.0 expected with 3.0-min timestep (year complete = 32.138%)\n",
      "1997 has 126687 out of 175200.0 expected with 3.0-min timestep (year complete = 72.3099%)\n",
      "1998 has 173314 out of 175200.0 expected with 3.0-min timestep (year complete = 98.9235%)\n",
      "1999 has 116761 out of 175200.0 expected with 3.0-min timestep (year complete = 66.6444%)\n",
      "2000 has 174125 out of 175680.0 expected with 3.0-min timestep (year complete = 99.1149%)\n",
      "2001 has 174752 out of 175200.0 expected with 3.0-min timestep (year complete = 99.7443%)\n",
      "2002 has 172037 out of 175200.0 expected with 3.0-min timestep (year complete = 98.1946%)\n",
      "2003 has 174462 out of 175200.0 expected with 3.0-min timestep (year complete = 99.5788%)\n",
      "2004 has 174274 out of 175680.0 expected with 3.0-min timestep (year complete = 99.1997%)\n",
      "2005 has 171538 out of 175200.0 expected with 3.0-min timestep (year complete = 97.9098%)\n",
      "2006 has 165021 out of 175200.0 expected with 3.0-min timestep (year complete = 94.1901%)\n",
      "2007 has 174594 out of 175200.0 expected with 3.0-min timestep (year complete = 99.6541%)\n",
      "2008 has 174851 out of 175680.0 expected with 3.0-min timestep (year complete = 99.5281%)\n",
      "2009 has 508404 out of 525600.0 expected with 1.0-min timestep (year complete = 96.7283%)\n",
      "2010 has 522545 out of 525600.0 expected with 1.0-min timestep (year complete = 99.4188%)\n",
      "2011 has 523493 out of 525600.0 expected with 1.0-min timestep (year complete = 99.5991%)\n",
      "2012 has 525658 out of 527040.0 expected with 1.0-min timestep (year complete = 99.7378%)\n",
      "2013 has 520918 out of 525600.0 expected with 1.0-min timestep (year complete = 99.1092%)\n",
      "2014 has 522963 out of 525600.0 expected with 1.0-min timestep (year complete = 99.4983%)\n",
      "2015 has 522006 out of 525600.0 expected with 1.0-min timestep (year complete = 99.3162%)\n",
      "2016 has 513433 out of 527040.0 expected with 1.0-min timestep (year complete = 97.4182%)\n",
      "2017 has 520497 out of 525600.0 expected with 1.0-min timestep (year complete = 99.0291%)\n",
      "2018 has 514475 out of 525600.0 expected with 1.0-min timestep (year complete = 97.8834%)\n",
      "2019 has 518692 out of 525600.0 expected with 1.0-min timestep (year complete = 98.6857%)\n",
      "2020 has 480938 out of 527040.0 expected with 1.0-min timestep (year complete = 91.2527%)\n",
      "2021 has 39422 out of 525600.0 expected with 1.0-min timestep (year complete = 7.50038%)\n"
     ]
    }
   ],
   "source": [
    "# how many years are missing data?\n",
    "weather_years = dict.fromkeys(years)\n",
    "for weather_year in weather_path.iterdir():\n",
    "    weather_df, weather_header = read_surfrad_year(weather_year)\n",
    "    year = weather_year.parts[-1]\n",
    "    dt = np.diff(weather_df.index).min().seconds/60\n",
    "    weather_years[year] = weather_df[['ghi', 'dhi', 'dni', 'solar_zenith', 'wind_speed', 'temp_air']].dropna()\n",
    "    num_recs = weather_years[year].shape[0]\n",
    "    daze = 365*24*60/dt\n",
    "    if calendar.isleap(int(year)):\n",
    "        daze += (24*60/dt)\n",
    "    frac_recs = num_recs/daze\n",
    "    print(f'{year} has {num_recs} out of {daze} expected with {dt}-min timestep (year complete = {frac_recs*100:g}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f4d6cf4-a9fc-4264-920e-7af86597fa1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>jday</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>dt</th>\n",
       "      <th>solar_zenith</th>\n",
       "      <th>ghi</th>\n",
       "      <th>ghi_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>temp_air</th>\n",
       "      <th>temp_air_flag</th>\n",
       "      <th>relative_humidity</th>\n",
       "      <th>relative_humidity_flag</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_speed_flag</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_direction_flag</th>\n",
       "      <th>pressure</th>\n",
       "      <th>pressure_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-01-01 00:00:00+00:00</th>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>104.86</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0</td>\n",
       "      <td>82.3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0</td>\n",
       "      <td>314.6</td>\n",
       "      <td>0</td>\n",
       "      <td>994.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-01 00:03:00+00:00</th>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>105.41</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.7</td>\n",
       "      <td>0</td>\n",
       "      <td>81.3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>321.7</td>\n",
       "      <td>0</td>\n",
       "      <td>994.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-01 00:06:00+00:00</th>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.10</td>\n",
       "      <td>105.95</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.6</td>\n",
       "      <td>0</td>\n",
       "      <td>81.6</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>327.9</td>\n",
       "      <td>0</td>\n",
       "      <td>994.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-01 00:09:00+00:00</th>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.15</td>\n",
       "      <td>106.50</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>0</td>\n",
       "      <td>994.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-01-01 00:12:00+00:00</th>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.20</td>\n",
       "      <td>107.05</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "      <td>81.9</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>340.4</td>\n",
       "      <td>0</td>\n",
       "      <td>995.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           year  jday  month  day  hour  minute    dt  \\\n",
       "2005-01-01 00:00:00+00:00  2005     1      1    1     0       0  0.00   \n",
       "2005-01-01 00:03:00+00:00  2005     1      1    1     0       3  0.05   \n",
       "2005-01-01 00:06:00+00:00  2005     1      1    1     0       6  0.10   \n",
       "2005-01-01 00:09:00+00:00  2005     1      1    1     0       9  0.15   \n",
       "2005-01-01 00:12:00+00:00  2005     1      1    1     0      12  0.20   \n",
       "\n",
       "                           solar_zenith  ghi  ghi_flag  ...  temp_air  \\\n",
       "2005-01-01 00:00:00+00:00        104.86 -3.9         0  ...      12.5   \n",
       "2005-01-01 00:03:00+00:00        105.41 -3.7         0  ...      12.7   \n",
       "2005-01-01 00:06:00+00:00        105.95 -3.7         0  ...      12.6   \n",
       "2005-01-01 00:09:00+00:00        106.50 -3.6         0  ...      12.3   \n",
       "2005-01-01 00:12:00+00:00        107.05 -3.3         0  ...      12.3   \n",
       "\n",
       "                           temp_air_flag  relative_humidity  \\\n",
       "2005-01-01 00:00:00+00:00              0               82.3   \n",
       "2005-01-01 00:03:00+00:00              0               81.3   \n",
       "2005-01-01 00:06:00+00:00              0               81.6   \n",
       "2005-01-01 00:09:00+00:00              0               82.5   \n",
       "2005-01-01 00:12:00+00:00              0               81.9   \n",
       "\n",
       "                           relative_humidity_flag  wind_speed  \\\n",
       "2005-01-01 00:00:00+00:00                       0         4.6   \n",
       "2005-01-01 00:03:00+00:00                       0         4.1   \n",
       "2005-01-01 00:06:00+00:00                       0         3.5   \n",
       "2005-01-01 00:09:00+00:00                       0         3.1   \n",
       "2005-01-01 00:12:00+00:00                       0         3.0   \n",
       "\n",
       "                           wind_speed_flag  wind_direction  \\\n",
       "2005-01-01 00:00:00+00:00                0           314.6   \n",
       "2005-01-01 00:03:00+00:00                0           321.7   \n",
       "2005-01-01 00:06:00+00:00                0           327.9   \n",
       "2005-01-01 00:09:00+00:00                0           334.0   \n",
       "2005-01-01 00:12:00+00:00                0           340.4   \n",
       "\n",
       "                           wind_direction_flag  pressure  pressure_flag  \n",
       "2005-01-01 00:00:00+00:00                    0     994.7              0  \n",
       "2005-01-01 00:03:00+00:00                    0     994.8              0  \n",
       "2005-01-01 00:06:00+00:00                    0     994.9              0  \n",
       "2005-01-01 00:09:00+00:00                    0     994.9              0  \n",
       "2005-01-01 00:12:00+00:00                    0     995.0              0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2005\n",
    "weather_years = list(weather_path.iterdir())\n",
    "df, header = read_surfrad_year(weather_years[10])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84dd9ff4-2d9c-413d-aee9-1e9f7f2f8a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = np.diff(df.index)\n",
    "dt.mean().seconds/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53fed9bb-0e89-4672-806e-c12b6d9973d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175200.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24*60/3*365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f914840b-c845-4ba9-a007-884cec5ba8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175200"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2005-01-01 00:00:00+00:00', '2005-01-01 00:03:00+00:00',\n",
       "               '2005-01-01 00:06:00+00:00', '2005-01-01 00:09:00+00:00',\n",
       "               '2005-01-01 00:12:00+00:00', '2005-01-01 00:15:00+00:00',\n",
       "               '2005-01-01 00:18:00+00:00', '2005-01-01 00:21:00+00:00',\n",
       "               '2005-01-01 00:24:00+00:00', '2005-01-01 00:27:00+00:00',\n",
       "               ...\n",
       "               '2005-12-31 23:30:00+00:00', '2005-12-31 23:33:00+00:00',\n",
       "               '2005-12-31 23:36:00+00:00', '2005-12-31 23:39:00+00:00',\n",
       "               '2005-12-31 23:42:00+00:00', '2005-12-31 23:45:00+00:00',\n",
       "               '2005-12-31 23:48:00+00:00', '2005-12-31 23:51:00+00:00',\n",
       "               '2005-12-31 23:54:00+00:00', '2005-12-31 23:57:00+00:00'],\n",
       "              dtype='datetime64[ns, UTC]', length=175200, freq='3T')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time3T2005 = pd.date_range(start='2005-01-01 00:00', end='2005-12-31 23:59', freq='3T', tz='UTC')\n",
    "display(time3T2005.size)\n",
    "time3T2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c202a886-bc4e-4f2e-a670-93f31b41f843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2005-01-01 00:00:00+00:00', '2005-01-01 00:03:00+00:00',\n",
       "               '2005-01-01 00:06:00+00:00', '2005-01-01 00:09:00+00:00',\n",
       "               '2005-01-01 00:12:00+00:00', '2005-01-01 00:15:00+00:00',\n",
       "               '2005-01-01 00:18:00+00:00', '2005-01-01 00:21:00+00:00',\n",
       "               '2005-01-01 00:24:00+00:00', '2005-01-01 00:27:00+00:00',\n",
       "               ...\n",
       "               '2005-12-31 23:30:00+00:00', '2005-12-31 23:33:00+00:00',\n",
       "               '2005-12-31 23:36:00+00:00', '2005-12-31 23:39:00+00:00',\n",
       "               '2005-12-31 23:42:00+00:00', '2005-12-31 23:45:00+00:00',\n",
       "               '2005-12-31 23:48:00+00:00', '2005-12-31 23:51:00+00:00',\n",
       "               '2005-12-31 23:54:00+00:00', '2005-12-31 23:57:00+00:00'],\n",
       "              dtype='datetime64[ns, UTC]', length=174861, freq=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedf792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff6cfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d09e574",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.temp_air.plot(figsize=(16, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f44219",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATITUDE = header['latitude']\n",
    "LONGITUDE = header['longitude']\n",
    "ELEVATION = header['elevation']\n",
    "TIMES = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5e7c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get solar position\n",
    "sp = pvlib.solarposition.get_solarposition(\n",
    "        TIMES, LATITUDE, LONGITUDE)\n",
    "solar_zenith = sp.apparent_zenith.values\n",
    "solar_azimuth = sp.azimuth.values\n",
    "zenith = sp.zenith.values\n",
    "ghi = df.ghi.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c482cdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the calculated zenith from SURFRAD\n",
    "ze_mbe = 100 * (\n",
    "    sum(solar_zenith - df.solar_zenith.values)\n",
    "    / sum(df.solar_zenith.values))\n",
    "print(f'zenith MBE: {ze_mbe}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7fa705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get irrad components\n",
    "irrad = pvlib.irradiance.erbs(ghi, zenith, TIMES)\n",
    "dni = irrad.dni.values\n",
    "dhi = irrad.dhi.values\n",
    "kt = irrad.kt.values  # clearness index\n",
    "\n",
    "# calculate irradiance inputs\n",
    "dni_extra = pvlib.irradiance.get_extra_radiation(TIMES).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2ecd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate air temp\n",
    "year_start = weather_years[10].parts[-1]\n",
    "TL = pvlib.clearsky.lookup_linke_turbidity(TIMES, LATITUDE, LONGITUDE)\n",
    "AM = pvlib.atmosphere.get_relative_airmass(solar_zenith)\n",
    "PRESS = pvlib.atmosphere.alt2pres(ELEVATION)\n",
    "AMA = pvlib.atmosphere.get_absolute_airmass(AM, PRESS)\n",
    "CS = pvlib.clearsky.ineichen(solar_zenith, AMA, TL, ELEVATION, dni_extra)\n",
    "\n",
    "# estimate air temp\n",
    "est_air_temp, temp_adj, ghi_ratio, daily_delta_temp, cs_temp_air = \\\n",
    "    estimate_air_temp(year_start, df,LATITUDE, LONGITUDE, CS)\n",
    "temp_air = est_air_temp['Adjusted Temp (C)'].loc[TIMES].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899048e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ghi_ratio.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66de8805",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_air_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c03a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2, 1, sharex=True, figsize=(16, 10))\n",
    "df.temp_air.plot(ax=ax[0], label='SURFRAD')\n",
    "est_air_temp[['Clear Sky Temperature (C)', 'Adjusted Temp (C)']].plot(ax=ax[0])\n",
    "ax[0].legend()\n",
    "CS.ghi.plot(ax=ax[1], label='CS')\n",
    "df.ghi.plot(ax=ax[1])\n",
    "ax[1].legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74dfc65",
   "metadata": {},
   "source": [
    "## Load SURFRAD daily weather data\n",
    "Each day is in a separate file. We already read this in using pvlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493772b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many days are in this file\n",
    "day_files = {int(d.parts[-1][5:-4]) for d in weather_years[10].iterdir()}\n",
    "len(day_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bfe22b-fa30-45c1-8d39-9e235aeee081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing days\n",
    "missing_days = set(range(1, 366)) - day_files\n",
    "missing_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f909fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8536f5",
   "metadata": {},
   "source": [
    "## Sanity check\n",
    "Look at a few timestamps around solar noon and display only a handful of columns:\n",
    "* direct normal irradiance (DNI): `'dni'`\n",
    "* global horizontal irradiance (GHI): `'ghi'`\n",
    "* diffuse horizontal irradiance (DHI): `'dhi'`\n",
    "* solar zenith: `'solar_zenith'`\n",
    "* wind speed: `'wind_speed'`\n",
    "* air temperature: `'temp_air'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf7cb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view a few timestamps to sanity check (E. Tufte, ...)\n",
    "data_cols = ['dni', 'ghi', 'dhi', 'solar_zenith', 'wind_speed', 'temp_air']\n",
    "df['2005-07-07T12:09:00-06:00':'2005-07-07T12:18:00-06:00'][data_cols]  # <-- XXX: pick dates for each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f1e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[data_cols].plot(figsize=(16, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecdf31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = irrad.dni.plot(figsize=(16, 10), label='Erbs')\n",
    "ax = df.dni.plot(ax=ax, label='SURFRAD')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2ca88a-67d3-4aef-bfc1-0ac11afab24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = irrad.dhi.plot(figsize=(16, 10), label='Erbs')\n",
    "ax = df.dhi.plot(ax=ax, label='SURFRAD')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942fc923",
   "metadata": {},
   "source": [
    "## Data quality\n",
    "Do some basic quality checking:\n",
    "1. no irradiance should be negative\n",
    "2. the DHI has to be the same as\n",
    "    $$GHI - DNI \\cos \\left( \\theta \\right)$$\n",
    "\n",
    "Then plot a sample day and take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289eb395",
   "metadata": {},
   "outputs": [],
   "source": [
    "surfrad_dni = np.maximum(0, df['dni'])\n",
    "surfrad_ghi = np.maximum(0, df['ghi'])\n",
    "surfrad_dif = np.maximum(0, df['dhi'])\n",
    "surfrad_zerad = np.radians(df['solar_zenith'])\n",
    "dhi_calc = pd.Series(np.maximum(0, surfrad_ghi - surfrad_dni*np.cos(surfrad_zerad)), name='DHI calc')\n",
    "irr_check = pd.concat([surfrad_dni, surfrad_ghi, surfrad_dif, dhi_calc], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc91672",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = irr_check['2005-07-01':'2005-07-04'].plot(figsize=(16, 10))  # <-- XXX: pick dates for each month\n",
    "irrad['2005-07-01':'2005-07-04'][['dni', 'dhi']].plot(style=['--', ':'], ax=ax)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4aca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = irr_check['2005-11-01':'2005-11-04'].plot(figsize=(16, 10))  # <-- XXX: pick dates for each month\n",
    "irrad['2005-11-01':'2005-11-04'][['dni', 'dhi']].plot(style=['--', ':'], ax=ax)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d3798d",
   "metadata": {},
   "source": [
    "## assembling weather file\n",
    "To model the output we need the following columns:\n",
    "1. datetime as ISO8601 but no nanoseconds or timezone\n",
    "2. GHI\n",
    "2. DHI (_AKA_: DIF)\n",
    "3. Temp\n",
    "4. WS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae79019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get other parameters needed for modeling like windspeed and air temp\n",
    "surfrad_wspd = df['wind_speed']\n",
    "surfrad_tair = df['temp_air']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed3049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.concat([surfrad_ghi, surfrad_dif, surfrad_tair, surfrad_wspd], axis=1)\n",
    "weather.index.name = 'datetime'\n",
    "weather.columns = ['GHI', 'DIF', 'Temp', 'WS']\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fa556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.loc['2005-01-01T08:21:00-06:00']  # <-- XXX: pick dates for each month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8dd5a0",
   "metadata": {},
   "source": [
    "## Simulate 5-minute sampled satellite data\n",
    "Choose instantaneous records every five minutes. Choose approximately the middle of the 5-minute sampling interval. Since these are 1-minute timestamps already, the closest to the middle is either the 2nd or 3rd minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcfb914",
   "metadata": {},
   "outputs": [],
   "source": [
    "every5min = list(range(3, 60, 6))\n",
    "every5min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071bfa69",
   "metadata": {},
   "source": [
    "### Shift index\n",
    "We need the timestamp to be at the start of the sampling interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793af560",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather5inst = weather[weather.index.minute.isin(every5min)].shift(freq='-3min')\n",
    "weather5inst60min = weather5inst.resample('H').mean()\n",
    "weather5inst60min['2005-01-07T06:00:00-06:00':'2005-01-07T18:00:00-06:00']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44363ac2",
   "metadata": {},
   "source": [
    "## Ditto for every 15-minutes\n",
    "Repeat for 15 minute intervals. Same dilemma, the closest record to the middle of the interval is either the 7th or 8th minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68df9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "every15min = list(range(6, 60, 15))\n",
    "every15min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fafb65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather15inst = weather[weather.index.minute.isin(every15min)].shift(freq='-6min')\n",
    "weather15inst60min = weather15inst.resample('H').mean()\n",
    "weather15inst60min['2005-01-07T06:00:00-06:00':'2005-01-07T18:00:00-06:00']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424c0b8f",
   "metadata": {},
   "source": [
    "## Ditto 60-minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb28279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather30inst = weather[weather.index.minute.isin([15, 45])].shift(freq='-15min')\n",
    "weather30inst60min = weather30inst.resample('H').mean()\n",
    "weather30inst60min['2005-01-07T06:00:00-06:00':'2005-01-07T18:00:00-06:00']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2511d534",
   "metadata": {},
   "source": [
    "# Visual Comparison of different sampling intervals\n",
    "How do these look compared to each other? Are they shifted correctly? Are they on the same order? Do they capture the variability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8736bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = weather['2005-01-07T06:00:00-06:00':'2005-01-07T18:00:00-06:00']['GHI'].plot()\n",
    "weather5inst['2005-01-07T06:00:00-06:00':'2005-01-07T18:00:00-06:00']['GHI'].shift(freq='3min').plot(ax=ax, marker='o', ms=5)\n",
    "weather15inst['2005-01-07T06:00:00-06:00':'2005-01-07T18:00:00-06:00']['GHI'].shift(freq='6min').plot(ax=ax, marker='o', ms=10)\n",
    "weather30inst['2005-01-07T06:00:00-06:00':'2005-01-07T18:00:00-06:00']['GHI'].shift(freq='15min').plot(ax=ax, marker='o', ms=15)\n",
    "plt.legend(['1-inst', '5-inst', '15-inst', '30-inst'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8191fc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = weather['2017-07-07 06:00':'2017-07-07 18:00']['GHI'].plot()\n",
    "weather5inst['2017-07-07 06:00':'2017-07-07 18:00']['GHI'].shift(freq='2min').plot(ax=ax, marker='o', ms=5)\n",
    "weather15inst['2017-07-07 06:00':'2017-07-07 18:00']['GHI'].shift(freq='7min').plot(ax=ax, marker='o', ms=10)\n",
    "weather30inst['2017-07-07 06:00':'2017-07-07 18:00']['GHI'].shift(freq='15min').plot(ax=ax, marker='o', ms=15)\n",
    "plt.legend(['1-inst', '5-inst', '15-inst', '30-inst'])\n",
    "plt.title('Instantaneous measurements taken at various sampling rates')\n",
    "plt.ylabel('GHI $[W/m^2]$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea92fc9",
   "metadata": {},
   "source": [
    "## Hourly averages from instantaneously sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5a20a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = weather.resample('H').mean().shift(freq='30min')['2017-01-07 06:00':'2017-01-07 18:00']['GHI'].plot(marker='o')\n",
    "weather5inst60min.shift(freq='30min')['2017-01-07 06:00':'2017-01-07 18:00']['GHI'].plot(ax=ax, marker='o')\n",
    "weather15inst60min.shift(freq='30min')['2017-01-07 06:00':'2017-01-07 18:00']['GHI'].plot(ax=ax, marker='o')\n",
    "weather30inst60min.shift(freq='30min')['2017-01-07 06:00':'2017-01-07 18:00']['GHI'].plot(ax=ax, marker='o')\n",
    "plt.legend(['1-inst_60-min', '5-inst_60-min', '15-inst_60-min', '30-inst_60-min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b75a22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = weather.resample('H').mean().shift(freq='30min')['2017-07-07 06:00':'2017-07-07 18:00']['GHI'].plot(marker='o')\n",
    "weather5inst60min.shift(freq='30min')['2017-07-07 06:00':'2017-07-07 18:00']['GHI'].plot(ax=ax, marker='o')\n",
    "weather15inst60min.shift(freq='30min')['2017-07-07 06:00':'2017-07-07 18:00']['GHI'].plot(ax=ax, marker='o')\n",
    "weather30inst60min.shift(freq='30min')['2017-07-07 06:00':'2017-07-07 18:00']['GHI'].plot(ax=ax, marker='o')\n",
    "plt.legend(['1-inst_60-min', '5-inst_60-min', '15-inst_60-min', '30-inst_60-min'])\n",
    "plt.title('Simulated satellite data averaged hourly from instantaneous measurements at various sampling rates')\n",
    "plt.ylabel('GHI $[W/m^2]$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b62e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.resample('H').mean()['2017-01-07 06:00':'2017-01-07 18:00']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505d8bed",
   "metadata": {},
   "source": [
    "## Compare 15-minute time averaged to 15-minute instantaneous\n",
    "How do shorter sampling intervals compare to time averaged values? Starting with 1-minute data, average every 15-minutes and compare to picking a single instantaneous record every 15 minutes, starting at the 7th minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a25e22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = weather.resample('15T').mean().shift(freq='450s')['2017-01-07 06:00':'2017-01-07 18:00']['GHI'].plot(marker='o')\n",
    "weather15inst['2017-01-07 06:00':'2017-01-07 18:00']['GHI'].shift(freq='7min').plot(ax=ax, marker='o')\n",
    "plt.legend(['1-inst_15-min', '15-inst'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eced0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = weather.resample('15T').mean().shift(freq='450s')['2017-07-07 06:00':'2017-07-07 18:00']['GHI'].plot(marker='o')\n",
    "weather15inst['2017-07-07 06:00':'2017-07-07 18:00']['GHI'].shift(freq='7min').plot(ax=ax, marker='o')\n",
    "plt.legend(['1-inst_15-min', '15-inst'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82888c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.resample('15T').mean()['2017-01-07 10:30':'2017-01-07 13:30']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c759dad5",
   "metadata": {},
   "source": [
    "# save output\n",
    "Save the files we need to run SolarFarmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edbcca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "month = 'allmonths'\n",
    "output_dir = pathlib.Path(f'instantaneous_{month}')\n",
    "output_dir.mkdir(exist_ok=False)  # <-- January is already done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6acb576",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather5inst.dropna().to_csv(output_dir / f'NIST_{month}-2017_5-inst.tab', sep='\\t')\n",
    "weather5inst60min.dropna().to_csv(output_dir / f'NIST_{month}-2017_5-inst_60-min.tab', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e10f37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather15inst.dropna().to_csv(output_dir / f'NIST_{month}-2017_15-inst.tab', sep='\\t')\n",
    "weather15inst60min.dropna().to_csv(output_dir / f'NIST_{month}-2017_15-inst_60-min.tab', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9509461",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather30inst.dropna().to_csv(output_dir / f'NIST_{month}-2017_30-inst.tab', sep='\\t')\n",
    "weather30inst60min.dropna().to_csv(output_dir / f'NIST_{month}-2017_30-inst_60-min.tab', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120cd20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather60inst = weather[weather.index.minute.isin([30])].shift(freq='-30min')\n",
    "weather60inst['2017-01-07 06:00':'2017-01-07 18:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152627f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather60inst.dropna().to_csv(output_dir / f'NIST_{month}-2017_60-inst.tab', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04dd3cc",
   "metadata": {},
   "source": [
    "# Time Averaged\n",
    "This is the original clipping error problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9d4e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.dropna().to_csv(output_dir / f'NIST_{month}-2017_1-min.tab', sep='\\t')\n",
    "weather.resample('5T').mean().dropna().to_csv(output_dir / f'NIST_{month}-2017_5-min.tab', sep='\\t')\n",
    "weather.resample('15T').mean().dropna().to_csv(output_dir / f'NIST_{month}-2017_15-min.tab', sep='\\t')\n",
    "weather.dropna().resample('30T').mean().dropna().to_csv(output_dir / f'NIST_{month}-2017_30-min.tab', sep='\\t')\n",
    "weather.resample('H').mean().dropna().to_csv(output_dir / f'NIST_{month}-2017_60-min.tab', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf594d93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
